{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Analytics - Assignment 2  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written (text) solution provide your answer in Markdown in appropriate cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to use the print() function. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "- Assignment 2 extends Assignment 1 on credit card applications. \n",
    "\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME_TOTAL   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day(0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Answer using both print() function and in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of rows in application record: 438557\n",
      "Amount of rows in credit record: 1048575\n",
      "There are 438510 unique bank clients in the application record\n",
      "There are 45985 unique bank clients in the credit record\n",
      "The amount of rows in df are 777715 and there are 36457 unique bank clients\n"
     ]
    }
   ],
   "source": [
    "# ---- Question 1 part 1 ------\n",
    "import pandas as pd\n",
    "df_application = pd.read_csv('data/application_record.csv')\n",
    "df_credit = pd.read_csv('data/credit_record.csv')\n",
    "\n",
    "# ---- Question 1 part 2 ----\n",
    "print('Amount of rows in application record:', len(df_application))\n",
    "print('Amount of rows in credit record:', len(df_credit))\n",
    "\n",
    "# ---- Question 1 part 3 ----\n",
    "print('There are',df_application['ID'].nunique(), 'unique bank clients in the application record')\n",
    "print('There are',df_credit['ID'].nunique(), 'unique bank clients in the credit record')\n",
    "\n",
    "# ---- Question 1 part 4 ----\n",
    "df = pd.merge(df_application, df_credit, on = 'ID', how = 'inner')\n",
    "\n",
    "# ---- Question 1 part 5 ----\n",
    "print('The amount of rows in df are', len(df),'and there are',df['ID'].nunique(), 'unique bank clients')\n",
    "#print('There are',df['ID'].nunique(), 'unique bank clients in the df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Written answers for question 1\n",
    "\n",
    "Task 2 Response: There are 438,557 rows in df_application and 1,048,575 rows in df_credit \n",
    "\n",
    "Task 3 Response :There are 438,510 unique bank clients in df_application and 45,985 unique bank clients in df_credit\n",
    "\n",
    "##### Question 1 Part 6\n",
    "\n",
    "Multiple rows of `ID` are different as they we have now joined the credit record data onto the application records through the IDs, linking the rows that share the same ID's in both the credit and application record. So some will have more information attached because they existed in both records which are now displayed in the current dataframe `df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "2. Create a new numpy array named `list_of_defaults` containing *unique* `ID` numbers for the clients who have `STATUS` = 1 in any of the last 12 months in the dataset. (2 marks) \n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` are in `list_of_defaults`, keeping only one row for each `ID` (i.e. eliminate rows with duplicate `ID`s while keeping the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (Hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "5. Increase `df_final` to a total of 4,000 rows by adding rows from `df` with unique `ID`s (nonduplicated `ID`s) which are not in `list_of_defaults`. To do this start adding the rows from the beginning of `df`. (Hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. How many clients with  overdue payments of more than 29 days and how many clients with less than 29 days overdue payments are there in `df_final`? Answer using both print() function and in Markdown text.(1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of rows in df_final are 1833\n",
      "Number of clients with overdue payments more than 29 days is:  2167\n",
      "Number of clients with overdue payments less than 29 days is:  1833\n"
     ]
    }
   ],
   "source": [
    "# ---- Question 2 part 1 ----\n",
    "import numpy as np\n",
    "status_mapping = {'C':0,'X':0,'0':0, '1':1,'2':1,'3':1,'4':1,'5':1}\n",
    "df['STATUS'] = df['STATUS'].map(status_mapping).astype(int)\n",
    "\n",
    "#print('unique rows in df', len(df['ID'].unique()))\n",
    "\n",
    "# ---- Question 2 part 2 ----\n",
    "list_of_defaults = np.array(df['ID'].loc[(df['STATUS']==1)&(df['MONTHS_BALANCE']>=-12)].unique())\n",
    "#print('defaults', len(list_of_defaults))\n",
    "\n",
    "# ---- Question 2 part 3 ----\n",
    "df_final = pd.DataFrame(df.loc[(df['ID'].isin(list_of_defaults))])\n",
    " #print('before dupes', len(df_final))\n",
    "df_final.drop_duplicates(subset='ID', inplace=True, keep = 'first')\n",
    "print('The amount of rows in df_final are', len(df_final))\n",
    "\n",
    "# ---- Question 2 part 4 ----\n",
    "df_final = df_final.assign(y=lambda x: 1)\n",
    "df_final\n",
    "\n",
    "# ---- Question 2 part 5 ----\n",
    "add_rows = df[(~df['ID'].isin(df_final))&(~df['ID'].isin(list_of_defaults))].drop_duplicates(subset='ID',keep='first')\n",
    "df_final = pd.concat([df_final, add_rows], ignore_index=True)\n",
    "df_final= df_final.loc[:3999]\n",
    "\n",
    "# ---- Question 2 part 6 ----\n",
    "df_final['y'] = df_final['y'].fillna(0)\n",
    "df_final['y'] = df_final['y'].astype(int)\n",
    "\n",
    "df_final = df_final.drop(['STATUS'], axis=1 )\n",
    "df_final = df_final.drop(['MONTHS_BALANCE'], axis=1)\n",
    "\n",
    "# How many clients with overdue payments of more than 29 days and how many clients with \n",
    "# less than 29 days overdue payments are there in `df_final`? Answer using both print() function and in Markdown text.\n",
    "print('Number of clients with overdue payments more than 29 days is: ', sum(df_final['y']==0))\n",
    "print('Number of clients with overdue payments less than 29 days is: ', sum(df_final['y']==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 \n",
    "There are 1833 rows in df_final after removing duplicate rows.\n",
    "\n",
    "The number of clients with overdue payments of more than 29 days is 2,167 whilst the number of clients with overdue payments under 29 days is 1,833."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "- Delete `ID` column from `df_final` (1 marks)\n",
    "- Of the remaining variables in `df_final` and assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable, how many variable are of numeric and nominal types? Provide lists of all numeric and nominal variables. (6)\n",
    "- Using an appropriate function find and comment on the missing values in `df_final`, i.e. how many variables and how many observations? (3 marks)   \n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(['ID'], axis=1)\n",
    "\n",
    "\n",
    "missing_values_col = df_final.isna().sum()\n",
    "#print(missing_values_col)\n",
    "#df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Variables:\n",
    "\n",
    "- CNT_CHILDREN\n",
    "- AMT_INCOME_TOTAL\n",
    "- DAYS_BIRTH\n",
    "- DAYS_EMPLOYED\n",
    "- COUNT_FAM_MEMBERS\n",
    "\n",
    "Nominal Vairbales:\n",
    "\n",
    "- CODE_GENDER\n",
    "- FLAG_OWN_CAR\n",
    "- FLAG_OWN_REALTY\n",
    "- NAME_INCOME_TYPE\n",
    "- NAME_FAMILY_STATUS\n",
    "- NAME_HOUSING_TYPE\n",
    "- FLAG_MOBIL\n",
    "- FLAG_WORK_PHONE\n",
    "- FLAG_PHONE\n",
    "- FLAG_EMAIL\n",
    "- OCCUPATION_TYPE\n",
    "- y\n",
    "\n",
    "It seems that there are 3 columns containing null values, these columns are: `CNT_CHILDREN`, `NAME_EDUCATION_TYPE`, `OCCUPATION_TYPE`. `CNT_CHILDREN` has 74 null obeservations, whilst `NAME_EDUCATION_TYPE`,`OCCUPATION_TYPE` have both 1831 and 1167 null observations respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "- Use an appropriate `pandas` function to impute missing values in `df_final` (10 marks)\n",
    "    - Be careful when deciding which method to use to replace missing observations \n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "- Briefly explain what you have done and why. (5 marks)\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['CNT_CHILDREN'].fillna(df_final['CNT_CHILDREN'].mode()[0], inplace=True)\n",
    "df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0], inplace=True)\n",
    "df_final['OCCUPATION_TYPE'].fillna(df_final['OCCUPATION_TYPE'].mode()[0], inplace=True)\n",
    "#df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I have done is replace all the NaN values in each column with the mode of that column. Using the mode in the case is more applicable as using the mean presents complications. As mean is a numerical output (the average of all outputs) it would result in a decimal (float) for the `CNT_CHILDREN` column and would not work in the string columns of `NAME_EDUCATION_TYPE` and `OCCUPATION_TYPE`. Using the mode which is the most common response in the column makes it versatile for both numerical and nominal results, so it is more applicable in this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_mapping = {'Lower secondary':1,'Secondary / secondary special':2,'Incomplete higher':3, 'Higher education':4}\n",
    "df_final['NAME_EDUCATION_TYPE'] = df_final['NAME_EDUCATION_TYPE'].map(education_mapping).astype(int)\n",
    "#df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_gender = pd.get_dummies(df_final['CODE_GENDER'], prefix='GENDER', prefix_sep='_',drop_first=True)\n",
    "dummy_car = pd.get_dummies(df_final['FLAG_OWN_CAR'], prefix='OWN_CAR', prefix_sep='_',drop_first=True)\n",
    "dummy_realty = pd.get_dummies(df_final['FLAG_OWN_REALTY'], prefix='OWN_REALTY', prefix_sep='_',drop_first=True)\n",
    "dummy_income = pd.get_dummies(df_final['NAME_INCOME_TYPE'], drop_first=True)\n",
    "dummy_family = pd.get_dummies(df_final['NAME_FAMILY_STATUS'], drop_first=True)\n",
    "dummy_housing = pd.get_dummies(df_final['NAME_HOUSING_TYPE'], drop_first=True)\n",
    "dummy_occupation = pd.get_dummies(df_final['OCCUPATION_TYPE'], drop_first=True)\n",
    "\n",
    "df_final = df_final.drop(['CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_INCOME_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE'],axis=1)\n",
    "\n",
    "df_final = df_final.join(dummy_gender)\n",
    "df_final = df_final.join(dummy_car)\n",
    "df_final = df_final.join(dummy_realty)\n",
    "df_final = df_final.join(dummy_income)\n",
    "df_final = df_final.join(dummy_family)\n",
    "df_final = df_final.join(dummy_housing)\n",
    "df_final = df_final.join(dummy_occupation)\n",
    "\n",
    "#df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "- Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "- Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(df_final['y'], order = 'C')\n",
    "X = df_final.drop(['y'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "- Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 70% train and 30% test datasets (2.5 marks) \n",
    "    - Set random_state to 7 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "- Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 7, stratify = y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Support Vector Classifier and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "- Train a Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `linear` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- Train another Support Vector Classifier on standardised data (3 marks)\n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "- What can you say about the presence of nonlinearities in the dataset? (4 marks)\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear kernel accuracy on train data = 0.645\n",
      "Linear kernel accuracy on test data = 0.634\n",
      "RBF kernel accuracy on train data = 0.777\n",
      "RBF kernel accuracy on test data = 0.723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# kernel set to linear\n",
    "svm = SVC(kernel='linear', random_state=7)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "print(f'Linear kernel accuracy on train data = {svm.score(X_train_scaled, y_train):.3f}')\n",
    "print(f'Linear kernel accuracy on test data = {svm.score(X_test_scaled, y_test):.3f}')\n",
    "\n",
    "# kernel set to rbf\n",
    "svm = SVC(kernel='rbf', random_state=7)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "print(f'RBF kernel accuracy on train data = {svm.score(X_train_scaled, y_train):.3f}')\n",
    "print(f'RBF kernel accuracy on test data = {svm.score(X_test_scaled, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the returned accuracies after running a linear kernel and a radial basis function (rbf) kernel, there is evidence of nonlinearities in the dataset as the `rbf` kernel produced a higher accuracy. This means that the dataset is not linearly separable and is likely more closely clustered together as there was a misclassification of 27.7% in the `rbf` model in contrast to the 36.6% misclassification`linear` model. This would suggest that the whether a client will default is determined by a combination of the predictors in the X array and will be in different regions depending on on the client instead of having a linear result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 10**\n",
    "\n",
    "- Extract 2 linear principal components from the standardised features using an appropriate `sklearn` library (5 marks)\n",
    "- Train a Support Vector Classifier on the computed principal components (5 marks) \n",
    "    - Use `rbf` kernel and set `random_state` to 7 (don't change any other parameters)\n",
    "- Compute and print training and test dataset accuracies (5 marks)\n",
    "- What can you say about the ability of the 2 principal components to compress the information contained in the features matrix `X`, and why? (5 marks)     \n",
    "\n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA RBF kernel accuracy on train data = 0.582\n",
      "PCA RBF kernel accuracy on test data = 0.577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=7)\n",
    "svm.fit(X_train_pca, y_train)\n",
    "print(f'PCA RBF kernel accuracy on train data = {svm.score(X_train_pca, y_train):.3f}')\n",
    "print(f'PCA RBF kernel accuracy on test data = {svm.score(X_test_pca, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your text answer here ----\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
